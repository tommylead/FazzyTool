"""
Module x·ª≠ l√Ω vi·ªác g·ªçi API Gemini ƒë·ªÉ sinh prompt t·ª± ƒë·ªông.
"""

import os
import json
from typing import Dict, Any, Optional
from datetime import datetime

import google.generativeai as genai
from dotenv import load_dotenv


class GeminiPromptGenerator:
    """L·ªõp x·ª≠ l√Ω vi·ªác g·ªçi API Gemini ƒë·ªÉ sinh prompt t·ª± ƒë·ªông."""
    
    def __init__(self, output_dir: str = "prompts"):
        """Kh·ªüi t·∫°o API key t·ª´ bi·∫øn m√¥i tr∆∞·ªùng."""
        load_dotenv()
        self.api_key = os.getenv("GEMINI_API_KEY")
        self.output_dir = output_dir
        
        # T·∫°o th∆∞ m·ª•c prompts n·∫øu ch∆∞a c√≥
        os.makedirs(self.output_dir, exist_ok=True)
        
        if not self.api_key:
            raise ValueError("GEMINI_API_KEY kh√¥ng t√¨m th·∫•y trong file .env")
            
        genai.configure(api_key=self.api_key)
        self.model = genai.GenerativeModel('gemini-1.5-flash')
        
    def generate_prompt(self, topic: str, prompt_id: Optional[str] = None, save_to_file: bool = True) -> Dict[str, Any]:
        """
        Sinh prompt t·ª´ Gemini d·ª±a tr√™n ch·ªß ƒë·ªÅ ƒë·∫ßu v√†o.
        
        Args:
            topic: Ch·ªß ƒë·ªÅ ti·∫øng Vi·ªát l√†m ƒë·∫ßu v√†o
            prompt_id: ID/s·ªë th·ª© t·ª± cho prompt (t·ª± ƒë·ªông t·∫°o n·∫øu None)
            save_to_file: C√≥ l∆∞u v√†o file hay kh√¥ng
            
        Returns:
            Dict ch·ª©a c√°c prompt cho ·∫£nh v√† video + th√¥ng tin file
        """
        try:
            # T·∫°o prompt_id n·∫øu kh√¥ng c√≥
            if not prompt_id:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                prompt_id = f"prompt_{timestamp}"
            
            system_prompt = """
            B·∫°n l√† tr·ª£ l√Ω AI chuy√™n t·∫°o prompt ƒë·ªÉ sinh ·∫£nh v√† video AI.
            T·ª´ ch·ªß ƒë·ªÅ ng∆∞·ªùi d√πng cung c·∫•p, h√£y t·∫°o ra c√°c prompt ph√π h·ª£p.
            
            Lu√¥n tr·∫£ v·ªÅ k·∫øt qu·∫£ ch√≠nh x√°c theo ƒë·ªãnh d·∫°ng JSON sau:
            {
              "image_prompt": "Chi ti·∫øt prompt cho AI sinh ·∫£nh (ti·∫øng Anh)",
              "video_prompt": "Chi ti·∫øt prompt cho AI sinh video (ti·∫øng Anh)",
              "video_duration": "5s ho·∫∑c 10s",
              "video_ratio": "1:1, 16:9, ho·∫∑c 9:16 t√πy thu·ªôc v√†o n·ªôi dung"
            }
            
            H∆∞·ªõng d·∫´n:
            1. Prompt ph·∫£i b·∫±ng ti·∫øng Anh ƒë·ªÉ AI t·∫°o n·ªôi dung t·ªët nh·∫•t
            2. M√¥ t·∫£ chi ti·∫øt v·ªÅ visual style, m√†u s·∫Øc, g√≥c nh√¨n, ch·ªß th·ªÉ
            3. Cho video: th√™m chuy·ªÉn ƒë·ªông, transitions, camera movement
            4. Ch·ªçn th·ªùi l∆∞·ª£ng h·ª£p l√Ω: 5s cho n·ªôi dung ƒë∆°n gi·∫£n, 10s cho ph·ª©c t·∫°p
            5. Ch·ªçn t·ª∑ l·ªá khung h√¨nh ph√π h·ª£p v·ªõi n·ªôi dung (1:1 vu√¥ng, 16:9 ngang, 9:16 d·ªçc)
            
            Ch·ªâ tr·∫£ v·ªÅ JSON, kh√¥ng th√™m b·∫•t k·ª≥ ch√∫ th√≠ch n√†o kh√°c.
            """
            
            prompt = f"Ch·ªß ƒë·ªÅ: {topic}\n\nT·∫°o prompt sinh ·∫£nh v√† video AI t·ª´ ch·ªß ƒë·ªÅ tr√™n."
            
            response = self.model.generate_content(
                [system_prompt, prompt],
                generation_config={
                    "temperature": 0.7,
                    "top_p": 0.95,
                    "response_mime_type": "application/json",
                }
            )
            
            # X·ª≠ l√Ω ph·∫£n h·ªìi
            result_text = response.text
            
            # ƒê√¥i khi Gemini c√≥ th·ªÉ th√™m c√°c markdown code block, lo·∫°i b·ªè ch√∫ng
            if "```json" in result_text:
                result_text = result_text.split("```json")[1].split("```")[0].strip()
            
            # Parse JSON
            result_data = json.loads(result_text)
            
            # Ki·ªÉm tra ƒë·ªãnh d·∫°ng
            required_keys = ["image_prompt", "video_prompt", "video_duration", "video_ratio"]
            for key in required_keys:
                if key not in result_data:
                    raise ValueError(f"Thi·∫øu tr∆∞·ªùng '{key}' trong k·∫øt qu·∫£ t·ª´ Gemini")
            
            # Th√™m metadata
            result_data.update({
                "topic": topic,
                "prompt_id": prompt_id,
                "generated_at": datetime.now().isoformat(),
                "generated_by": "gemini-1.5-flash"
            })
            
            # L∆∞u v√†o file n·∫øu ƒë∆∞·ª£c y√™u c·∫ßu
            if save_to_file:
                file_path = self.save_prompt_to_file(result_data, prompt_id)
                result_data["file_path"] = file_path
                print(f"üíæ ƒê√£ l∆∞u prompt: {file_path}")
            
            return result_data
            
        except Exception as e:
            error_msg = str(e)
            
            # X·ª≠ l√Ω c√°c l·ªói ph·ªï bi·∫øn
            if "quota" in error_msg.lower() or "exceeded" in error_msg.lower():
                raise Exception(
                    f"‚ùå Gemini API ƒë√£ v∆∞·ª£t qu√° quota mi·ªÖn ph√≠!\n"
                    f"üí° Gi·∫£i ph√°p:\n"
                    f"1. T·∫°o API key m·ªõi t·∫°i: https://makersuite.google.com/app/apikey\n"
                    f"2. Ho·∫∑c s·ª≠ d·ª•ng ch·∫ø ƒë·ªô File v·ªõi prompt c√≥ s·∫µn\n"
                    f"3. Ch·ªù ƒë·∫øn th√°ng sau ƒë·ªÉ quota reset\n"
                    f"Chi ti·∫øt l·ªói: {error_msg}"
                )
            elif "api" in error_msg.lower() and "key" in error_msg.lower():
                raise Exception(
                    f"‚ùå API Key kh√¥ng h·ª£p l·ªá!\n"
                    f"üí° Ki·ªÉm tra l·∫°i GEMINI_API_KEY trong file .env\n"
                    f"L·∫•y API key m·ªõi t·∫°i: https://makersuite.google.com/app/apikey\n"
                    f"Chi ti·∫øt l·ªói: {error_msg}"
                )
            else:
                raise Exception(f"‚ùå L·ªói khi g·ªçi Gemini API: {error_msg}")
            
    def save_prompt_to_file(self, prompt_data: Dict[str, Any], prompt_id: str) -> str:
        """L∆∞u prompt v√†o file JSON v·ªõi t√™n c√≥ th·ª© t·ª± r√µ r√†ng."""
        try:
            # T·∫°o t√™n file v·ªõi format: prompt_001_topic.json
            topic_safe = prompt_data.get('topic', 'unknown')[:30]  # Gi·ªõi h·∫°n ƒë·ªô d√†i
            topic_safe = "".join(c for c in topic_safe if c.isalnum() or c in (' ', '-', '_')).strip()
            topic_safe = topic_safe.replace(' ', '_')
            
            filename = f"{prompt_id}_{topic_safe}.json"
            file_path = os.path.join(self.output_dir, filename)
            
            with open(file_path, "w", encoding="utf-8") as f:
                json.dump(prompt_data, f, ensure_ascii=False, indent=2)
                
            return file_path
        except Exception as e:
            raise Exception(f"L·ªói khi l∆∞u prompt: {str(e)}")
    
    def generate_batch_prompts(self, topics: list, start_index: int = 1) -> list:
        """
        Sinh nhi·ªÅu prompt t·ª´ danh s√°ch topic v√† l∆∞u th√†nh file c√≥ th·ª© t·ª±.
        
        Args:
            topics: Danh s√°ch c√°c ch·ªß ƒë·ªÅ
            start_index: S·ªë b·∫Øt ƒë·∫ßu ƒë√°nh s·ªë (m·∫∑c ƒë·ªãnh: 1)
            
        Returns:
            List c√°c prompt data v·ªõi th√¥ng tin file
        """
        results = []
        
        for i, topic in enumerate(topics, start_index):
            try:
                # T·∫°o prompt_id c√≥ th·ª© t·ª±
                prompt_id = f"prompt_{i:03d}"  # 001, 002, 003...
                
                print(f"üîÆ [{i}/{len(topics) + start_index - 1}] ƒêang sinh prompt cho: {topic}")
                
                prompt_data = self.generate_prompt(topic, prompt_id, save_to_file=True)
                results.append(prompt_data)
                
                print(f"‚úÖ Ho√†n th√†nh prompt {prompt_id}")
                
            except Exception as e:
                print(f"‚ùå L·ªói sinh prompt {i}: {e}")
                results.append({
                    "topic": topic,
                    "prompt_id": f"prompt_{i:03d}",
                    "error": str(e),
                    "status": "failed"
                })
        
        # T·∫°o file summary
        self._create_batch_summary(results)
        
        return results
    
    def _create_batch_summary(self, results: list):
        """T·∫°o file t√≥m t·∫Øt batch generation."""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        summary_file = os.path.join(self.output_dir, f"batch_summary_{timestamp}.json")
        
        summary = {
            "generated_at": datetime.now().isoformat(),
            "total_prompts": len(results),
            "successful": len([r for r in results if "error" not in r]),
            "failed": len([r for r in results if "error" in r]),
            "prompts": results
        }
        
        with open(summary_file, "w", encoding="utf-8") as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
            
        print(f"üìä ƒê√£ t·∫°o file t√≥m t·∫Øt: {summary_file}") 